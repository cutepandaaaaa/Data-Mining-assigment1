import time  # 导入时间模块
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler

print("computing...")
# 设置随机种子以确保可重复性
torch.manual_seed(0)

# 1. 数据加载
column_names = [
    "age", "workclass", "fnlwgt", "education", "education_num", "marital_status",
    "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss",
    "hours_per_week", "native_country", "income"
]
data = pd.read_csv('adult.data', header=None, names=column_names, na_values=' ?', skipinitialspace=True)
test_data = pd.read_csv('adult.test', header=None, names=column_names, na_values=' ?', skipinitialspace=True, skiprows=1)

# 2. 数据预处理
# 去掉缺失值
data.dropna(inplace=True)
test_data.dropna(inplace=True)

# 处理目标变量
data['income'] = data['income'].map({'<=50K': 0, '>50K': 1})
test_data['income'] = test_data['income'].map({'<=50K.': 0, '>50K.': 1})

# 特征和标签
X = data.drop('income', axis=1)
y = data['income']

# 对分类特征进行编码
categorical_features = X.select_dtypes(include=['object']).columns.tolist()
numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()

# 创建预处理管道
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())  # 添加标准化
        ]), numeric_features),
        ('cat', OneHotEncoder(sparse_output=False), categorical_features)
    ])

X_processed = preprocessor.fit_transform(X)
y_processed = y.values

# 3. 数据分割
X_train, X_valid, y_train, y_valid = train_test_split(X_processed, y_processed, test_size=0.2, random_state=0)

# 4. 创建数据加载器
train_tensor = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))  # 使用 FloatTensor
valid_tensor = TensorDataset(torch.FloatTensor(X_valid), torch.FloatTensor(y_valid))
train_loader = DataLoader(train_tensor, batch_size=64, shuffle=True)
valid_loader = DataLoader(valid_tensor, batch_size=64, shuffle=False)

# 5. 定义神经网络
class NeuralNetwork(nn.Module):
    def __init__(self, input_size):
        super(NeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, 256)  # 增加节点数
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 64)
        self.fc4 = nn.Linear(64, 1)  # 输出层只有一个节点，因为这是二分类问题
        self.activation = nn.ReLU()
        self.dropout = nn.Dropout(0.5)  # 添加 Dropout

    def forward(self, x):
        x = self.fc1(x)
        x = self.activation(x)
        x = self.dropout(x)  # 添加 Dropout
        x = self.fc2(x)
        x = self.activation(x)
        x = self.dropout(x)  # 添加 Dropout
        x = self.fc3(x)
        x = self.activation(x)
        x = self.fc4(x)  # 不应用 Sigmoid，在计算损失时再使用
        return x

# 6. 初始化模型、损失函数和优化器
model = NeuralNetwork(X_processed.shape[1])
criterion = nn.BCEWithLogitsLoss()  # 使用 logits 作为损失函数
optimizer = optim.Adam(model.parameters(), lr=0.0001)  # 减小学习率

# 7. 训练模型
num_epochs = 50  # 增加训练轮数
start_time = time.time()  # 记录开始时间

for epoch in range(num_epochs):
    model.train()
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()  # 输出的形状是 [batch_size]
        loss = criterion(outputs, labels)  # 不需要 float()，因为已经是 FloatTensor
        loss.backward()
        optimizer.step()
    
    # 验证模型
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for inputs, labels in valid_loader:
            outputs = model(inputs).squeeze()
            val_loss += criterion(outputs, labels).item()
    val_loss /= len(valid_loader)
    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss:.4f}')

end_time = time.time()  # 记录结束时间
training_time = end_time - start_time  # 计算训练时间
print(f'Training Time: {training_time:.2f} seconds')  # 打印训练时间

# 8. 测试模型
test_processed = preprocessor.transform(test_data.drop('income', axis=1))
test_tensor = torch.FloatTensor(test_processed)
model.eval()
with torch.no_grad():
    test_outputs = model(test_tensor).squeeze()
    test_predictions = (torch.sigmoid(test_outputs) > 0.5).long()  # 在这里应用 Sigmoid

# 计算准确率
test_accuracy = (test_predictions.numpy() == test_data['income'].values).mean()
print(f'Test Accuracy: {test_accuracy:.4f}')
